{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhushanrajs/distribution_factors_pySR/blob/main/df_skew_correction_PySR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "gRbbfqK0GREg"
      },
      "source": [
        "# Symbolic Regression"
      ],
      "id": "gRbbfqK0GREg"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GIeFXS0F0zww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572395fb-1341-4281-b2c9-1214dbfe243d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Julia 1.8.5 on the current Colab Runtime...\n",
            "2024-07-18 06:35:38 URL:https://julialang-s3.julialang.org/bin/linux/x64/1.8/julia-1.8.5-linux-x86_64.tar.gz [130873886/130873886] -> \"/tmp/julia.tar.gz\" [1]\n",
            "Installing PyCall.jl...\n",
            "\u001b[32m\u001b[1m  Installing\u001b[22m\u001b[39m known registries into `~/.julia`\n",
            "\u001b[?25h\u001b[2K\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[S\u001b[1A\u001b[2K\u001b[1G\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PrecompileTools ─ v1.2.1\n",
            "\u001b[S\u001b[1A\u001b[2K\u001b[1G\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Parsers ───────── v2.8.1\n",
            "\u001b[S\u001b[1A\u001b[2K\u001b[1G\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m JSON ──────────── v0.21.4\n",
            "\u001b[S\u001b[1A\u001b[2K\u001b[1G\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MacroTools ────── v0.5.13\n",
            "\u001b[S\u001b[1A\u001b[2K\u001b[1G\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Conda ─────────── v1.10.2\n",
            "\u001b[S\u001b[1A\u001b[2K\u001b[1G\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m VersionParsing ── v1.3.0\n",
            "\u001b[S\u001b[1A\u001b[2K\u001b[1G\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Preferences ───── v1.4.3\n",
            "\u001b[S\u001b[1A\u001b[2K\u001b[1G\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PyCall ────────── v1.96.4\n",
            "\u001b[?25h\u001b[2K\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.8/Project.toml`\n",
            " \u001b[90m [438e738f] \u001b[39m\u001b[92m+ PyCall v1.96.4\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.8/Manifest.toml`\n",
            " \u001b[90m [8f4d0f93] \u001b[39m\u001b[92m+ Conda v1.10.2\u001b[39m\n",
            " \u001b[90m [682c06a0] \u001b[39m\u001b[92m+ JSON v0.21.4\u001b[39m\n",
            " \u001b[90m [1914dd2f] \u001b[39m\u001b[92m+ MacroTools v0.5.13\u001b[39m\n",
            " \u001b[90m [69de0a69] \u001b[39m\u001b[92m+ Parsers v2.8.1\u001b[39m\n",
            " \u001b[90m [aea7be01] \u001b[39m\u001b[92m+ PrecompileTools v1.2.1\u001b[39m\n",
            " \u001b[90m [21216c6a] \u001b[39m\u001b[92m+ Preferences v1.4.3\u001b[39m\n",
            " \u001b[90m [438e738f] \u001b[39m\u001b[92m+ PyCall v1.96.4\u001b[39m\n",
            " \u001b[90m [81def892] \u001b[39m\u001b[92m+ VersionParsing v1.3.0\u001b[39m\n",
            " \u001b[90m [0dad84c5] \u001b[39m\u001b[92m+ ArgTools v1.1.1\u001b[39m\n",
            " \u001b[90m [56f22d72] \u001b[39m\u001b[92m+ Artifacts\u001b[39m\n",
            " \u001b[90m [2a0f44e3] \u001b[39m\u001b[92m+ Base64\u001b[39m\n",
            " \u001b[90m [ade2ca70] \u001b[39m\u001b[92m+ Dates\u001b[39m\n",
            " \u001b[90m [f43a241f] \u001b[39m\u001b[92m+ Downloads v1.6.0\u001b[39m\n",
            " \u001b[90m [7b1f6079] \u001b[39m\u001b[92m+ FileWatching\u001b[39m\n",
            " \u001b[90m [b27032c2] \u001b[39m\u001b[92m+ LibCURL v0.6.3\u001b[39m\n",
            " \u001b[90m [8f399da3] \u001b[39m\u001b[92m+ Libdl\u001b[39m\n",
            " \u001b[90m [37e2e46d] \u001b[39m\u001b[92m+ LinearAlgebra\u001b[39m\n",
            " \u001b[90m [d6f4376e] \u001b[39m\u001b[92m+ Markdown\u001b[39m\n",
            " \u001b[90m [a63ad114] \u001b[39m\u001b[92m+ Mmap\u001b[39m\n",
            " \u001b[90m [ca575930] \u001b[39m\u001b[92m+ NetworkOptions v1.2.0\u001b[39m\n",
            " \u001b[90m [de0858da] \u001b[39m\u001b[92m+ Printf\u001b[39m\n",
            " \u001b[90m [9a3f8284] \u001b[39m\u001b[92m+ Random\u001b[39m\n",
            " \u001b[90m [ea8e919c] \u001b[39m\u001b[92m+ SHA v0.7.0\u001b[39m\n",
            " \u001b[90m [9e88b42a] \u001b[39m\u001b[92m+ Serialization\u001b[39m\n",
            " \u001b[90m [fa267f1f] \u001b[39m\u001b[92m+ TOML v1.0.0\u001b[39m\n",
            " \u001b[90m [cf7118a7] \u001b[39m\u001b[92m+ UUIDs\u001b[39m\n",
            " \u001b[90m [4ec0a83e] \u001b[39m\u001b[92m+ Unicode\u001b[39m\n",
            " \u001b[90m [e66e0078] \u001b[39m\u001b[92m+ CompilerSupportLibraries_jll v1.0.1+0\u001b[39m\n",
            " \u001b[90m [deac9b47] \u001b[39m\u001b[92m+ LibCURL_jll v7.84.0+0\u001b[39m\n",
            " \u001b[90m [29816b5a] \u001b[39m\u001b[92m+ LibSSH2_jll v1.10.2+0\u001b[39m\n",
            " \u001b[90m [c8ffd9c3] \u001b[39m\u001b[92m+ MbedTLS_jll v2.28.0+0\u001b[39m\n",
            " \u001b[90m [14a3606d] \u001b[39m\u001b[92m+ MozillaCACerts_jll v2022.2.1\u001b[39m\n",
            " \u001b[90m [4536629a] \u001b[39m\u001b[92m+ OpenBLAS_jll v0.3.20+0\u001b[39m\n",
            " \u001b[90m [83775a58] \u001b[39m\u001b[92m+ Zlib_jll v1.2.12+3\u001b[39m\n",
            " \u001b[90m [8e850b90] \u001b[39m\u001b[92m+ libblastrampoline_jll v5.1.1+0\u001b[39m\n",
            " \u001b[90m [8e850ede] \u001b[39m\u001b[92m+ nghttp2_jll v1.48.0+0\u001b[39m\n",
            "\u001b[?25l\u001b[S\u001b[1A\u001b[2K\u001b[1G\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m Conda ─→ `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/b19db3927f0db4151cb86d073689f2428e524576/build.log`\n",
            "\u001b[S\u001b[1A\u001b[2K\u001b[1G\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m PyCall → `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/9816a3826b0ebf49ab4926e2b18842ad8b5c8f04/build.log`\n",
            "\u001b[?25h\u001b[2K\u001b[?25l\u001b[S\u001b[1A\u001b[2K\u001b[1G\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m Conda ─→ `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/b19db3927f0db4151cb86d073689f2428e524576/build.log`\n",
            "\u001b[S\u001b[1A\u001b[2K\u001b[1G\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m PyCall → `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/9816a3826b0ebf49ab4926e2b18842ad8b5c8f04/build.log`\n",
            "\u001b[?25h\u001b[2KSuccess\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.8.5\"\n",
        "export JULIA_PKG_PRECOMPILE_AUTO=0\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  echo \"Installing PyCall.jl...\"\n",
        "  julia -e 'using Pkg; Pkg.add(\"PyCall\"); Pkg.build(\"PyCall\")'\n",
        "  julia -e 'println(\"Success\")'\n",
        "\n",
        "fi"
      ],
      "id": "GIeFXS0F0zww"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install PySR and PyTorch-Lightning:"
      ],
      "metadata": {
        "id": "i04jgyGPybhm"
      },
      "id": "i04jgyGPybhm"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EhMRSZEYFPLz",
        "outputId": "78b78f36-6897-41c3-f220-fb65c75fbfe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.1/80.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -Uq pysr pytorch_lightning --quiet"
      ],
      "id": "EhMRSZEYFPLz"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install julia"
      ],
      "metadata": {
        "id": "nAfYt2PQgYMQ",
        "outputId": "9b8c442d-fc19-4803-f53f-1a3f77d3c343",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nAfYt2PQgYMQ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting julia\n",
            "  Downloading julia-0.6.2-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: julia\n",
            "Successfully installed julia-0.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from julia import Julia\n",
        "\n",
        "julia = Julia(compiled_modules=False, threads=\"auto\")\n",
        "from julia import Main\n",
        "from julia.tools import redirect_output_streams\n",
        "\n",
        "redirect_output_streams()"
      ],
      "metadata": {
        "id": "aOK8KeJmyqyS"
      },
      "id": "aOK8KeJmyqyS",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-0QbxyK1_51",
        "outputId": "aaa873de-c79c-400f-9c23-f261676fa255",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[juliapkg] Found dependencies: /usr/local/lib/python3.10/dist-packages/pysr/juliapkg.json\n",
            "[juliapkg] Found dependencies: /usr/local/lib/python3.10/dist-packages/juliapkg/juliapkg.json\n",
            "[juliapkg] Found dependencies: /usr/local/lib/python3.10/dist-packages/juliacall/juliapkg.json\n",
            "[juliapkg] Locating Julia ~1.6.7, ~1.7, ~1.8, ~1.9, =1.10.0, ~1.10.3\n",
            "[juliapkg] Using Julia 1.8.5 at /usr/local/bin/julia\n",
            "[juliapkg] Using Julia project at /root/.julia/environments/pyjuliapkg\n",
            "[juliapkg] Installing packages:\n",
            "           julia> import Pkg\n",
            "           julia> Pkg.Registry.update()\n",
            "           julia> Pkg.add([Pkg.PackageSpec(name=\"SymbolicRegression\", uuid=\"8254be44-1295-4e6a-a16d-46603ac705cb\"), Pkg.PackageSpec(name=\"Serialization\", uuid=\"9e88b42a-f829-5b0c-bbe9-9e923198166b\"), Pkg.PackageSpec(name=\"PythonCall\", uuid=\"6099a3de-0909-46bc-b1f4-468b9a2dfc0d\")])\n",
            "           julia> Pkg.resolve()\n",
            "           julia> Pkg.precompile()\n"
          ]
        }
      ],
      "source": [
        "import pysr\n",
        "\n",
        "# We don't precompile in colab because compiled modules are incompatible static Python libraries:\n",
        "pysr.install(precompile=False)"
      ],
      "id": "J-0QbxyK1_51"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vFpyRxmhFqeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "478c783e-173b-4570-9b55-b4ea03e6db87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
          ]
        }
      ],
      "source": [
        "import sympy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from pysr import PySRRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import pickle\n"
      ],
      "id": "vFpyRxmhFqeH"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/bhushanrajs/distribution_factors_pySR/main/psc_i.csv')"
      ],
      "metadata": {
        "id": "dgwfHemQhGFD"
      },
      "id": "dgwfHemQhGFD",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head(5))"
      ],
      "metadata": {
        "id": "4i8ypMy4iIsB",
        "outputId": "ca129790-7bc9-4c4f-e178-64f2c1a0a473",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4i8ypMy4iIsB",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             model  skew girderName   L   D  w_oh    ts  S  \\\n",
            "0   Tx28-L_42-Nb_4-S_60-O_15-ts_85     0       Tx28  42  28   1.5   8.5  6   \n",
            "1  Tx28-L_42-Nb_4-S_60-O_15-ts_100     0       Tx28  42  28   1.5  10.0  6   \n",
            "2   Tx28-L_42-Nb_4-S_60-O_20-ts_85     0       Tx28  42  28   2.0   8.5  6   \n",
            "3  Tx28-L_42-Nb_4-S_60-O_20-ts_100     0       Tx28  42  28   2.0  10.0  6   \n",
            "4   Tx28-L_42-Nb_4-S_60-O_25-ts_85     0       Tx28  42  28   2.5   8.5  6   \n",
            "\n",
            "   Nb           Kg  ...     n_bm4      n_r1      n_r2      n_r3      n_r4  \\\n",
            "0   4  555508.7064  ...  0.000520  0.925505  0.086994  0.026596 -0.039095   \n",
            "1   4  588747.3095  ...  0.000889  0.923853  0.093144  0.036185 -0.053182   \n",
            "2   4  555508.7064  ...  0.000448  0.993568  0.023006  0.024837 -0.041411   \n",
            "3   4  588747.3095  ...  0.000803  0.991692  0.031001  0.033527 -0.056219   \n",
            "4   4  555508.7064  ...  0.000379  1.060984 -0.039607  0.022209 -0.043585   \n",
            "\n",
            "     sum_RY      d-G1      d-G2      d-G3          d-G4  \n",
            "0  0.000035  0.037370  0.016730  0.004557 -1.190000e-34  \n",
            "1  0.000035  0.032403  0.015338  0.004701 -1.620000e-34  \n",
            "2  0.000030  0.037898  0.015816  0.003978 -1.260000e-34  \n",
            "3  0.000035  0.032799  0.014651  0.004199 -1.720000e-34  \n",
            "4  0.000036  0.038521  0.014924  0.003400 -1.330000e-34  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['x_trial'] = ((df['S']+df['w_oh'])*np.tan(np.radians(df['skew'])))/df['L']\n",
        "\n",
        "girderName = df.loc[(df['skew'] == 0) & (df['ts'] == 8.5), 'girderName'].values\n",
        "L = df.loc[(df['skew'] == 0) & (df['ts'] == 8.5), 'L'].values\n",
        "D = df.loc[(df['skew'] == 0) & (df['ts'] == 8.5), 'D'].values\n",
        "S = df.loc[(df['skew'] == 0) & (df['ts'] == 8.5), 'S'].values\n",
        "w_oh = df.loc[(df['skew'] == 0) & (df['ts'] == 8.5), 'w_oh'].values\n",
        "ts = df.loc[(df['skew'] == 0) & (df['ts'] == 8.5), 'ts'].values\n",
        "Nb = df.loc[(df['skew'] == 0) & (df['ts'] == 8.5), 'Nb'].values\n",
        "Kg = df.loc[(df['skew'] == 0) & (df['ts'] == 8.5), 'Kg'].values\n",
        "skew = df.loc[(df['skew'] == 60), 'skew'].values * np.pi / 180\n",
        "O = (w_oh * 10).astype(int)\n",
        "tss = (ts * 10).astype(int)\n",
        "models = girderName + '-L_' + L.astype(str) + '-Nb_' + Nb.astype(str) + '-S_' + (S*10).astype(str) + '-O_' + O.astype(str) + '-ts_' + tss.astype(str)\n",
        "print(models)\n",
        "\n",
        "skews = [30, 45]\n",
        "sk_bm1_correction,sk_bm2_correction, sk_r1_correction, sk_r2_correction  = [], [], [], [],\n",
        "x_L, x_S, x_D, x_Nb, x_skew, x_w_oh, x_trial, x_tan_skew, x_AR = [], [], [], [], [], [], [], [], []\n",
        "\n",
        "for skew in skews:\n",
        "  for model in models:\n",
        "    skew_model = model + '-sk_' + str(skew)\n",
        "    normal_model = model\n",
        "    n_bm1_skewed = df.loc[(df['model'] == skew_model) , 'n_bm1'].values\n",
        "    n_bm1_normal = df.loc[(df['model'] == normal_model) , 'n_bm1'].values\n",
        "    n_bm2_skewed = df.loc[(df['model'] == skew_model) , 'n_bm2'].values\n",
        "    n_bm2_normal = df.loc[(df['model'] == normal_model) , 'n_bm2'].values\n",
        "    n_r1_skewed = df.loc[(df['model'] == skew_model) , 'n_r1'].values\n",
        "    n_r1_normal = df.loc[(df['model'] == normal_model) , 'n_r1'].values\n",
        "    n_r2_skewed = df.loc[(df['model'] == skew_model) , 'n_r2'].values\n",
        "    n_r2_normal = df.loc[(df['model'] == normal_model) , 'n_r2'].values\n",
        "    sk_bm1_correction.extend(n_bm1_skewed / n_bm1_normal)\n",
        "    sk_bm2_correction.extend(n_bm2_skewed / n_bm2_normal)\n",
        "    sk_r1_correction.extend(n_r1_skewed / n_r1_normal)\n",
        "    sk_r2_correction.extend(n_r2_skewed / n_r2_normal)\n",
        "    x_L.extend(df.loc[(df['model'] == skew_model) , 'L'].values)\n",
        "    x_S.extend(df.loc[(df['model'] == skew_model) , 'S'].values)\n",
        "    x_D.extend(df.loc[(df['model'] == skew_model) , 'D'].values)\n",
        "    x_Nb.extend(df.loc[(df['model'] == skew_model) , 'Nb'].values)\n",
        "    x_skew.extend(df.loc[(df['model'] == skew_model) , 'skew'].values * np.pi / 180)\n",
        "    # x_tan_skew.extend(np.tan(df.loc[(df['model'] == skew_model) , 'skew'].values * np.pi / 180))\n",
        "    x_w_oh.extend(df.loc[(df['model'] == skew_model) , 'w_oh'].values)\n",
        "    x_trial.extend(df.loc[(df['model'] == skew_model) , 'x_trial'].values)\n"
      ],
      "metadata": {
        "id": "ECAjwXXwinpF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2201feef-e99e-4294-bd42-c4f946422941"
      },
      "id": "ECAjwXXwinpF",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tx28-L_42-Nb_4-S_60-O_15-ts_85' 'Tx28-L_42-Nb_4-S_60-O_20-ts_85'\n",
            " 'Tx28-L_42-Nb_4-S_60-O_25-ts_85' ... 'Tx84-L_210-Nb_7-S_120-O_36-ts_85'\n",
            " 'Tx84-L_210-Nb_7-S_120-O_48-ts_85' 'Tx84-L_210-Nb_7-S_120-O_60-ts_85']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_tan_skew = np.tan(x_skew)\n",
        "x_cos_skew = np.cos(x_skew)\n",
        "x_sin_skew = np.sin(x_skew)\n",
        "print(sk_r1_correction[2304:])\n",
        "print(x_skew)\n",
        "print(x_tan_skew)"
      ],
      "metadata": {
        "id": "fohrfJh8N5GL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c7d2ae-3991-453a-ca0e-e7c8128cfdc8"
      },
      "id": "fohrfJh8N5GL",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.5235987755982988, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483, 0.7853981633974483]\n",
            "[0.57735027 0.57735027 0.57735027 ... 1.         1.         1.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-06T00:43:54.847201Z",
          "iopub.status.busy": "2022-07-06T00:43:54.846876Z",
          "iopub.status.idle": "2022-07-06T00:43:54.851460Z",
          "shell.execute_reply": "2022-07-06T00:43:54.850804Z"
        },
        "id": "M16U5vbpGREq"
      },
      "outputs": [],
      "source": [
        "X = np.stack((x_L, x_S, x_w_oh, x_tan_skew), axis=-1)\n",
        "y = sk_r1_correction\n",
        "print(X.shape)\n",
        "# print(y.shape)\n",
        "print(X)"
      ],
      "id": "M16U5vbpGREq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Learn equations\n",
        "default_pysr_params = dict(\n",
        "    populations=50,\n",
        "    model_selection=\"best\",\n",
        ")\n",
        "\n",
        "# model = PySRRegressor(\n",
        "#     niterations=30,\n",
        "#     binary_operators=['+', '-', '*', '/', '^'],\n",
        "#     unary_operators=[\"square\", \"cube\", \"sqrt\"],\n",
        "#     **default_pysr_params\n",
        "# )\n",
        "\n",
        "model = PySRRegressor(\n",
        "    niterations=400,  # < Increase me for better results\n",
        "    binary_operators=['+', '-', '*', '/'],\n",
        "    unary_operators=[\"square\", \"sqrt\"],\n",
        "        # ^ Custom operator (julia syntax)\n",
        "    extra_sympy_mappings={\"inv\": lambda x: 1 / x,\n",
        "                          \"physics\": lambda x, y: x**2 / y},\n",
        "    # ^ Define operator for SymPy as well\n",
        "    loss=\"loss(prediction, target) = (prediction - target)^2\",\n",
        "    constraints = {'^':(-4,4),'mult' : (3,3)},\n",
        "    # ^ Custom loss function (julia syntax)\n",
        "    **default_pysr_params\n",
        ")"
      ],
      "metadata": {
        "id": "y7BuV8zexXeU",
        "outputId": "1cb5c283-b9cd-4da8-e50f-510bc041c24c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "y7BuV8zexXeU",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:915: FutureWarning: `loss` has been renamed to `elementwise_loss` in PySRRegressor. Please use that instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "HVzDu54ytB-H"
      },
      "id": "HVzDu54ytB-H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 8\n",
        "model.sympy(n)\n"
      ],
      "metadata": {
        "id": "uiYBCjzY6XWF"
      },
      "id": "uiYBCjzY6XWF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X,n)\n",
        "print(\"Default selection MSE:\", np.power(y_pred - y, 2).mean())\n",
        "r2 = r2_score(y_pred, y)\n",
        "print(f\"R²: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "VZdZ87DJOn_a"
      },
      "id": "VZdZ87DJOn_a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_line = [0.9, 1.8]\n",
        "y_line = [0.9, 1.8]\n",
        "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(5, 5), constrained_layout = True)\n",
        "ax1.scatter(x=y, y=y_pred, marker='o', c='none', edgecolor='b', label='Exterior Girder')\n",
        "ax1.plot(x_line, y_line, c = \"k\")\n",
        "ax1.set_title('Accuracy')\n",
        "ax1.legend()\n",
        "plt.xlim((0.9,1.8))\n",
        "plt.ylim((0.9,1.8))\n",
        "ax1.set_xlabel('Target $n_{r1}$')\n",
        "ax1.set_ylabel('Predicted $n_{r1}$')\n",
        "ax1.grid()"
      ],
      "metadata": {
        "id": "IchggoCQVQXW"
      },
      "id": "IchggoCQVQXW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(model.sympy(i))\n",
        "  y_pred = model.predict(X,i)\n",
        "  print(\"Default selection MSE:\", np.power(y_pred - y, 2).mean())\n",
        "  r2 = r2_score(y_pred, y)\n",
        "  print(f\"R²: {r2:.4f}\")\n",
        "  x_line = [0.9, 1.8]\n",
        "  y_line = [0.9, 1.8]\n",
        "  fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(5, 5), constrained_layout = True)\n",
        "  ax1.scatter(x=y, y=y_pred, marker='o', c='none', edgecolor='b', label='Exterior Girder')\n",
        "  ax1.plot(x_line, y_line, c = \"k\")\n",
        "  ax1.set_title('Accuracy')\n",
        "  ax1.legend()\n",
        "  plt.xlim((0.9,1.8))\n",
        "  plt.ylim((0.9,1.8))\n",
        "  ax1.set_xlabel('Target $n_{r1}$')\n",
        "  ax1.set_ylabel('Predicted $n_{r1}$')\n",
        "  ax1.grid()"
      ],
      "metadata": {
        "id": "1eOg9pBOY65M"
      },
      "id": "1eOg9pBOY65M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the  as a pickle file\n",
        "model_pkl_file = \"skew_correction_V_G1.pkl\"\n",
        "\n",
        "with open(model_pkl_file, 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "SssSvdvHp59M"
      },
      "id": "SssSvdvHp59M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model from pickle file\n",
        "with open(model_pkl_file, 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "# evaluate model\n",
        "y_predict = model.predict(X,n)\n",
        "\n",
        "# check results\n",
        "print(y_predict)"
      ],
      "metadata": {
        "id": "wiW4SQW0qA3b",
        "outputId": "73841ba6-ed41-4681-aed8-845744002818",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wiW4SQW0qA3b",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.09735977 1.07267283 1.05582327 ... 1.12907411 1.10970617 1.09691723]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.stack((x_L, x_S, x_w_oh, x_tan_skew), axis=-1)\n",
        "y = sk_r2_correction\n",
        "model.fit(X, y)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "OIHz3KcSnTRW",
        "outputId": "f4f57f9d-7f99-4427-e2b5-4ed2a4172e95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OIHz3KcSnTRW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:2582: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n",
            "[ Info: Started!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Expressions evaluated per second: 2.090e+04\n",
            "Head worker occupation: 14.9%\n",
            "Progress: 47 / 20000 total iterations (0.235%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "2           6.745e+03  7.971e+00  y = sqrt(0.16452)\n",
            "3           6.743e+03  2.558e-04  y = 1.8208 - x₂\n",
            "4           6.741e+03  3.384e-04  y = square(1.7956) - x₂\n",
            "5           6.741e+03  5.960e-07  y = 0.58728 - (x₂ - 2.6573)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.210e+04\n",
            "Head worker occupation: 11.8%\n",
            "Progress: 124 / 20000 total iterations (0.620%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.746e+03  1.594e+01  y = 1.225\n",
            "2           6.745e+03  1.039e-04  y = sqrt(0.16452)\n",
            "3           6.743e+03  2.558e-04  y = 1.8208 - x₂\n",
            "4           6.741e+03  3.384e-04  y = square(1.7956) - x₂\n",
            "5           6.741e+03  6.288e-05  y = (x₁ / x₂) - x₂\n",
            "8           6.740e+03  3.898e-05  y = sqrt(square(square(3.3141 - (0.81606 * x₂))))\n",
            "12          6.740e+03  6.974e-06  y = sqrt((((x₁ * x₁) + x₀) / x₁) / x₂) - x₂\n",
            "13          6.738e+03  2.339e-04  y = sqrt(square(((square(-3.2003) - sqrt(x₀)) * (x₃ + -2.4739)...\n",
            "                                  ) * x₃))\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.060e+04\n",
            "Head worker occupation: 11.1%\n",
            "Progress: 183 / 20000 total iterations (0.915%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.746e+03  1.594e+01  y = 1.225\n",
            "2           6.745e+03  1.039e-04  y = sqrt(0.16452)\n",
            "3           6.743e+03  2.558e-04  y = 1.8208 - x₂\n",
            "4           6.741e+03  3.384e-04  y = square(1.7956) - x₂\n",
            "5           6.741e+03  6.288e-05  y = (x₁ / x₂) - x₂\n",
            "8           6.740e+03  3.898e-05  y = sqrt(square(square(3.3141 - (0.81606 * x₂))))\n",
            "12          6.740e+03  6.974e-06  y = sqrt((((x₁ * x₁) + x₀) / x₁) / x₂) - x₂\n",
            "13          6.738e+03  2.339e-04  y = sqrt(square(((square(-3.2003) - sqrt(x₀)) * (x₃ + -2.4739)...\n",
            "                                  ) * x₃))\n",
            "16          6.737e+03  3.767e-05  y = sqrt(sqrt(square(sqrt(square((square(square(x₃)) / ((-1.17...\n",
            "                                  93 / 0.41583) + x₂)) * -0.40492)))))\n",
            "18          6.715e+03  1.640e-03  y = sqrt(((square(x₁) / x₀) / square((square(x₂) - x₂) - sqrt(...\n",
            "                                  x₀ * 0.48618))) / 0.48651)\n",
            "20          6.712e+03  2.338e-04  y = sqrt(((square(x₁) / (x₂ * x₀)) / square((square(x₂) - x₂) ...\n",
            "                                  - sqrt(x₀ * 0.48618))) / 0.21086)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.030e+04\n",
            "Head worker occupation: 11.1%\n",
            "Progress: 246 / 20000 total iterations (1.230%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.34822\n",
            "2           6.745e+03  -0.000e+00  y = sqrt(0.16452)\n",
            "3           6.742e+03  3.735e-04  y = 2.1105 - x₂\n",
            "4           6.741e+03  2.208e-04  y = square(1.7956) - x₂\n",
            "5           6.741e+03  6.288e-05  y = (x₁ / x₂) - x₂\n",
            "6           6.740e+03  2.241e-05  y = square(square(square(-1.3976)) - x₂)\n",
            "7           6.739e+03  2.448e-04  y = (-3.1735 + (16.291 / x₂)) - 2.8996\n",
            "10          6.738e+03  2.855e-05  y = square(3.3141 - (sqrt(square(0.81606)) * x₂)) - x₃\n",
            "13          6.738e+03  8.563e-06  y = sqrt(square(((square(-3.2003) - sqrt(x₀)) * (x₃ + -2.4739)...\n",
            "                                  ) * x₃))\n",
            "15          6.737e+03  6.023e-05  y = sqrt(sqrt(square((sqrt(2.4593) / (-0.70251 + (-2.1157 + x₂...\n",
            "                                  ))) / x₂)) / 0.33397)\n",
            "16          6.712e+03  3.732e-03  y = sqrt((square(x₁) / x₀) / square((square(x₂) - x₂) - sqrt(x...\n",
            "                                  ₀ * 0.48618)))\n",
            "18          6.712e+03  4.530e-06  y = sqrt(((square(x₁) / x₀) / square((square(x₂) - x₂) - sqrt(...\n",
            "                                  x₀ * 0.48618))) / 0.73441)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.410e+04\n",
            "Head worker occupation: 10.8%\n",
            "Progress: 332 / 20000 total iterations (1.660%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.742e+03  1.867e-04  y = 2.1105 - x₂\n",
            "4           6.741e+03  2.208e-04  y = square(1.7956) - x₂\n",
            "5           6.740e+03  1.793e-04  y = 6.2892 - (x₂ + x₂)\n",
            "7           6.739e+03  7.547e-05  y = (-3.1735 + (16.291 / x₂)) - 2.8996\n",
            "8           6.738e+03  8.428e-05  y = square(3.3141 - (x₂ * 0.81606)) - 0.81606\n",
            "10          6.738e+03  6.258e-07  y = square(3.3141 - (sqrt(square(0.81606)) * x₂)) - x₃\n",
            "11          6.738e+03  1.371e-05  y = square(3.3141 - (sqrt(square(0.81606)) * x₂)) - sqrt(x₃)\n",
            "13          6.736e+03  1.842e-04  y = (square((1.8209 - square(-0.34513 * x₂)) / 0.78814) - -0.0...\n",
            "                                  61709) - x₂\n",
            "14          6.735e+03  1.000e-04  y = sqrt(sqrt(square(square(square(-0.40492 - x₃)) / ((-1.1793...\n",
            "                                   / 0.41583) + x₂))))\n",
            "15          6.734e+03  1.881e-04  y = sqrt(sqrt(square((square(x₃ - -0.40492) / ((-1.1793 / 0.41...\n",
            "                                  583) + x₂)) * 0.41583)))\n",
            "16          6.712e+03  3.207e-03  y = sqrt((square(x₁) / x₀) / square((square(x₂) - x₂) - sqrt(x...\n",
            "                                  ₀ * 0.48618)))\n",
            "18          6.712e+03  1.362e-05  y = sqrt(((square(x₁) / x₀) / square((square(x₂) - x₂) - sqrt(...\n",
            "                                  x₀ * 0.48618))) / 0.90622)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.030e+04\n",
            "Head worker occupation: 10.5%\n",
            "Progress: 381 / 20000 total iterations (1.905%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "5           6.740e+03  8.861e-05  y = 6.2892 - (x₂ + x₂)\n",
            "7           6.739e+03  7.547e-05  y = (-3.1735 + (16.291 / x₂)) - 2.8996\n",
            "8           6.738e+03  8.428e-05  y = square(3.3141 - (x₂ * 0.81606)) - 0.81606\n",
            "10          6.738e+03  6.258e-07  y = square(3.3141 - (sqrt(square(0.81606)) * x₂)) - x₃\n",
            "11          6.738e+03  1.371e-05  y = square(3.3141 - (sqrt(square(0.81606)) * x₂)) - sqrt(x₃)\n",
            "12          6.735e+03  5.096e-04  y = (square(3.3141 - (sqrt(square(0.81606)) * x₂)) - x₃) * x₂\n",
            "15          6.729e+03  2.684e-04  y = sqrt((x₁ / x₀) / square((square(x₂) - x₂) - sqrt(x₀ * 0.48...\n",
            "                                  618)))\n",
            "16          6.712e+03  2.549e-03  y = sqrt((square(x₁) / x₀) / square((square(x₂) - x₂) - sqrt(x...\n",
            "                                  ₀ * 0.48618)))\n",
            "18          6.565e+03  1.106e-02  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 2.840e+04\n",
            "Head worker occupation: 9.8%\n",
            "Progress: 416 / 20000 total iterations (2.080%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "5           6.740e+03  8.861e-05  y = 6.2892 - (x₂ + x₂)\n",
            "7           6.739e+03  7.547e-05  y = (-3.1735 + (16.291 / x₂)) - 2.8996\n",
            "8           6.738e+03  8.428e-05  y = square(3.3141 - (x₂ * 0.81606)) - 0.81606\n",
            "10          6.738e+03  1.770e-05  y = square(3.3141 - (x₂ - (0.82295 * 0.81606))) - 0.81606\n",
            "12          6.735e+03  2.446e-04  y = (square(3.3141 - (sqrt(square(0.81606)) * x₂)) - x₃) * x₂\n",
            "15          6.729e+03  2.684e-04  y = sqrt((x₁ / x₀) / square((square(x₂) - x₂) - sqrt(x₀ * 0.48...\n",
            "                                  618)))\n",
            "16          6.712e+03  2.549e-03  y = sqrt((square(x₁) / x₀) / square((square(x₂) - x₂) - sqrt(x...\n",
            "                                  ₀ * 0.48618)))\n",
            "18          6.565e+03  1.106e-02  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 2.610e+04\n",
            "Head worker occupation: 9.7%\n",
            "Progress: 466 / 20000 total iterations (2.330%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "5           6.740e+03  8.861e-05  y = 6.2892 - (x₂ + x₂)\n",
            "7           6.739e+03  7.547e-05  y = (-3.1735 + (16.291 / x₂)) - 2.8996\n",
            "8           6.738e+03  8.428e-05  y = square(3.3141 - (x₂ * 0.81606)) - 0.81606\n",
            "10          6.738e+03  1.770e-05  y = square(3.3141 - (x₂ - (0.82295 * 0.81606))) - 0.81606\n",
            "12          6.735e+03  2.446e-04  y = (square(3.3141 - (sqrt(square(0.81606)) * x₂)) - x₃) * x₂\n",
            "13          6.724e+03  1.589e-03  y = sqrt(x₂ / square((square(x₂) - x₂) - sqrt(x₀ * 0.48618)))\n",
            "16          6.712e+03  5.883e-04  y = sqrt((square(x₁) / x₀) / square((square(x₂) - x₂) - sqrt(x...\n",
            "                                  ₀ * 0.48618)))\n",
            "17          6.711e+03  1.873e-04  y = sqrt((square(0.32785) / x₀) / square(square((square(x₂) - ...\n",
            "                                  x₂) - sqrt(x₀ * 0.48618))))\n",
            "18          6.565e+03  2.194e-02  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 2.240e+04\n",
            "Head worker occupation: 9.2%\n",
            "Progress: 515 / 20000 total iterations (2.575%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "5           6.740e+03  8.861e-05  y = 6.2892 - (x₂ + x₂)\n",
            "7           6.739e+03  7.547e-05  y = (-3.1735 + (16.291 / x₂)) - 2.8996\n",
            "8           6.738e+03  8.428e-05  y = square(3.3141 - (x₂ * 0.81606)) - 0.81606\n",
            "9           6.624e+03  1.711e-02  y = 0.98298 / ((3.3141 - (x₂ + -0.24967)) * 1.2014)\n",
            "10          6.617e+03  9.748e-04  y = 0.98298 / ((3.3141 - (x₂ + -0.24967)) * sqrt(1.2014))\n",
            "11          6.597e+03  3.157e-03  y = -0.18422 * sqrt(sqrt(square(x₂ / square(x₂ - 3.5758))))\n",
            "18          6.565e+03  6.797e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 2.860e+04\n",
            "Head worker occupation: 9.6%\n",
            "Progress: 625 / 20000 total iterations (3.125%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "4           6.740e+03  8.399e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "8           6.692e+03  2.298e-03  y = 1.7547 / ((square(x₂) * -0.70953) + x₁)\n",
            "9           6.624e+03  1.030e-02  y = 0.98298 / ((3.3141 - (x₂ + -0.24967)) * 1.2014)\n",
            "10          6.617e+03  9.748e-04  y = 0.98298 / ((3.3141 - (x₂ + -0.24967)) * sqrt(1.2014))\n",
            "11          6.597e+03  3.157e-03  y = -0.18422 * sqrt(sqrt(square(x₂ / square(x₂ - 3.5758))))\n",
            "18          6.565e+03  6.797e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 2.690e+04\n",
            "Head worker occupation: 9.5%\n",
            "Progress: 653 / 20000 total iterations (3.265%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "4           6.740e+03  8.399e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "8           6.692e+03  2.298e-03  y = 1.7547 / ((square(x₂) * -0.70953) + x₁)\n",
            "9           6.624e+03  1.030e-02  y = 0.98298 / ((3.3141 - (x₂ + -0.24967)) * 1.2014)\n",
            "10          6.617e+03  9.748e-04  y = 0.98298 / ((3.3141 - (x₂ + -0.24967)) * sqrt(1.2014))\n",
            "11          6.597e+03  3.157e-03  y = -0.18422 * sqrt(sqrt(square(x₂ / square(x₂ - 3.5758))))\n",
            "18          6.565e+03  6.797e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 2.630e+04\n",
            "Head worker occupation: 9.7%\n",
            "Progress: 698 / 20000 total iterations (3.490%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "4           6.740e+03  8.399e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "7           6.619e+03  8.957e-03  y = x₃ / (3.3141 - (x₂ + -0.24967))\n",
            "10          6.617e+03  8.636e-05  y = 0.98298 / ((3.3141 - (x₂ + -0.24967)) * sqrt(1.2014))\n",
            "11          6.597e+03  3.157e-03  y = -0.18422 * sqrt(sqrt(square(x₂ / square(x₂ - 3.5758))))\n",
            "18          6.565e+03  6.797e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 2.670e+04\n",
            "Head worker occupation: 9.8%\n",
            "Progress: 745 / 20000 total iterations (3.725%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "4           6.740e+03  8.399e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "7           6.611e+03  9.543e-03  y = 0.98298 / (3.3141 - (x₂ + -0.24967))\n",
            "9           6.591e+03  1.512e-03  y = (x₃ + x₃) / (3.3141 - (x₂ + -0.24967))\n",
            "18          6.565e+03  4.422e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 2.040e+04\n",
            "Head worker occupation: 9.7%\n",
            "Progress: 801 / 20000 total iterations (4.005%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "4           6.740e+03  8.399e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "7           6.611e+03  9.543e-03  y = 0.98298 / (3.3141 - (x₂ + -0.24967))\n",
            "9           6.591e+03  1.512e-03  y = (x₃ + x₃) / (3.3141 - (x₂ + -0.24967))\n",
            "18          6.565e+03  4.422e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.220e+04\n",
            "Head worker occupation: 9.6%\n",
            "Progress: 934 / 20000 total iterations (4.670%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "4           6.740e+03  8.399e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "7           6.611e+03  9.543e-03  y = 0.98298 / (3.3141 - (x₂ + -0.24967))\n",
            "9           6.590e+03  1.596e-03  y = (0.60279 + x₃) / (3.3141 - (x₂ + -0.24967))\n",
            "11          6.589e+03  9.481e-05  y = (sqrt(0.60279) + square(x₃)) / (3.3141 - (x₂ + -0.24967))\n",
            "18          6.565e+03  5.173e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "20          6.565e+03  2.891e-05  y = (x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * ...\n",
            "                                  sqrt(0.44394)) + sqrt(0.44394)) - x₂)) + 0.21085\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.560e+04\n",
            "Head worker occupation: 9.7%\n",
            "Progress: 1003 / 20000 total iterations (5.015%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "4           6.740e+03  8.399e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "6           6.730e+03  1.367e-03  y = x₃ / (square(1.8057) - x₂)\n",
            "7           6.611e+03  1.772e-02  y = 0.98298 / (3.3141 - (x₂ + -0.24967))\n",
            "8           6.600e+03  1.768e-03  y = sqrt(1.5583) / (3.3141 - (x₂ + -0.24967))\n",
            "9           6.590e+03  1.424e-03  y = (0.60279 + x₃) / (3.3141 - (x₂ + -0.24967))\n",
            "11          6.589e+03  9.481e-05  y = (sqrt(0.60279) + square(x₃)) / (3.3141 - (x₂ + -0.24967))\n",
            "18          6.565e+03  5.173e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "20          6.564e+03  5.535e-05  y = (x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * ...\n",
            "                                  sqrt(0.44394)) + sqrt(0.44394)) - x₂)) - -0.47106\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.520e+04\n",
            "Head worker occupation: 9.7%\n",
            "Progress: 1045 / 20000 total iterations (5.225%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "4           6.740e+03  8.399e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "6           6.730e+03  1.367e-03  y = x₃ / (square(1.8057) - x₂)\n",
            "7           6.611e+03  1.772e-02  y = 0.98298 / (3.3141 - (x₂ + -0.24967))\n",
            "8           6.600e+03  1.768e-03  y = sqrt(1.5583) / (3.3141 - (x₂ + -0.24967))\n",
            "9           6.590e+03  1.424e-03  y = (0.60279 + x₃) / (3.3141 - (x₂ + -0.24967))\n",
            "11          6.589e+03  9.481e-05  y = (sqrt(0.60279) + square(x₃)) / (3.3141 - (x₂ + -0.24967))\n",
            "18          6.565e+03  5.173e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "19          6.561e+03  5.868e-04  y = sqrt(x₃) / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.329...\n",
            "                                  2) * sqrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.910e+04\n",
            "Head worker occupation: 9.6%\n",
            "Progress: 1128 / 20000 total iterations (5.640%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "4           6.740e+03  8.399e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "6           6.730e+03  1.367e-03  y = x₃ / (square(1.8057) - x₂)\n",
            "7           6.611e+03  1.772e-02  y = 0.98298 / (3.3141 - (x₂ + -0.24967))\n",
            "8           6.600e+03  1.768e-03  y = sqrt(1.5583) / (3.3141 - (x₂ + -0.24967))\n",
            "9           6.590e+03  1.424e-03  y = (0.60279 + x₃) / (3.3141 - (x₂ + -0.24967))\n",
            "11          6.589e+03  9.481e-05  y = (sqrt(0.60279) + square(x₃)) / (3.3141 - (x₂ + -0.24967))\n",
            "18          6.565e+03  5.173e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "19          6.561e+03  5.868e-04  y = sqrt(x₃) / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.329...\n",
            "                                  2) * sqrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.380e+04\n",
            "Head worker occupation: 9.6%\n",
            "Progress: 1199 / 20000 total iterations (5.995%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "4           6.740e+03  8.399e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "6           6.730e+03  1.367e-03  y = x₃ / (square(1.8057) - x₂)\n",
            "7           6.611e+03  1.772e-02  y = 0.98298 / (3.3141 - (x₂ + -0.24967))\n",
            "8           6.600e+03  1.768e-03  y = sqrt(1.5583) / (3.3141 - (x₂ + -0.24967))\n",
            "9           6.590e+03  1.424e-03  y = (0.60279 + x₃) / (3.3141 - (x₂ + -0.24967))\n",
            "11          6.589e+03  9.481e-05  y = (sqrt(0.60279) + square(x₃)) / (3.3141 - (x₂ + -0.24967))\n",
            "18          6.565e+03  5.173e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "19          6.561e+03  5.868e-04  y = sqrt(x₃) / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.329...\n",
            "                                  2) * sqrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.310e+04\n",
            "Head worker occupation: 9.5%\n",
            "Progress: 1285 / 20000 total iterations (6.425%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "4           6.740e+03  8.399e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "6           6.730e+03  1.367e-03  y = x₃ / (square(1.8057) - x₂)\n",
            "7           6.588e+03  2.124e-02  y = 0.3725 / (x₂ - (x₃ / 0.27882))\n",
            "18          6.565e+03  3.165e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "19          6.561e+03  5.868e-04  y = sqrt(x₃) / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.329...\n",
            "                                  2) * sqrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.940e+04\n",
            "Head worker occupation: 9.6%\n",
            "Progress: 1389 / 20000 total iterations (6.945%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "4           6.740e+03  8.399e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "6           6.730e+03  1.367e-03  y = x₃ / (square(1.8057) - x₂)\n",
            "7           6.588e+03  2.124e-02  y = 0.3725 / (x₂ - (x₃ / 0.27882))\n",
            "18          6.565e+03  3.165e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "19          6.561e+03  5.868e-04  y = sqrt(x₃) / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.329...\n",
            "                                  2) * sqrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.880e+04\n",
            "Head worker occupation: 9.6%\n",
            "Progress: 1458 / 20000 total iterations (7.290%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "4           6.740e+03  8.399e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "6           6.730e+03  1.367e-03  y = x₃ / (square(1.8057) - x₂)\n",
            "7           6.588e+03  2.124e-02  y = 0.3725 / (x₂ - (x₃ / 0.27882))\n",
            "18          6.565e+03  3.165e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "19          6.561e+03  5.868e-04  y = sqrt(x₃) / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.329...\n",
            "                                  2) * sqrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.960e+04\n",
            "Head worker occupation: 9.5%\n",
            "Progress: 1542 / 20000 total iterations (7.710%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.982e-04  y = 3.34 - x₂\n",
            "4           6.740e+03  8.399e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "6           6.730e+03  1.367e-03  y = x₃ / (square(1.8057) - x₂)\n",
            "7           6.588e+03  2.124e-02  y = 0.3725 / (x₂ - (x₃ / 0.27882))\n",
            "18          6.565e+03  3.165e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "19          6.561e+03  5.868e-04  y = sqrt(x₃) / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.329...\n",
            "                                  2) * sqrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 4.720e+04\n",
            "Head worker occupation: 9.6%\n",
            "Progress: 1680 / 20000 total iterations (8.400%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.983e-04  y = 3.341 - x₂\n",
            "4           6.740e+03  8.393e-05  y = square(3.8329 - x₂)\n",
            "5           6.739e+03  2.442e-04  y = -6.0408 + (16.213 / x₂)\n",
            "6           6.730e+03  1.367e-03  y = x₃ / (square(1.8057) - x₂)\n",
            "7           6.588e+03  2.124e-02  y = 0.3725 / (x₂ - (x₃ / 0.27882))\n",
            "18          6.565e+03  3.165e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "19          6.561e+03  5.868e-04  y = sqrt(x₃) / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.329...\n",
            "                                  2) * sqrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 4.460e+04\n",
            "Head worker occupation: 9.6%\n",
            "Progress: 1760 / 20000 total iterations (8.800%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.983e-04  y = 3.3024 - x₂\n",
            "4           6.740e+03  8.381e-05  y = square(3.8329 - x₂)\n",
            "5           6.738e+03  2.960e-04  y = sqrt(square(9.0035 - x₁))\n",
            "6           6.730e+03  1.316e-03  y = x₃ / (square(1.8057) - x₂)\n",
            "7           6.588e+03  2.124e-02  y = 0.3725 / (x₂ - (x₃ / 0.27882))\n",
            "18          6.565e+03  3.165e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "19          6.561e+03  5.868e-04  y = sqrt(x₃) / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.329...\n",
            "                                  2) * sqrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 4.470e+04\n",
            "Head worker occupation: 9.7%\n",
            "Progress: 1842 / 20000 total iterations (9.210%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.983e-04  y = 3.3024 - x₂\n",
            "4           6.740e+03  8.381e-05  y = square(3.8329 - x₂)\n",
            "5           6.738e+03  2.960e-04  y = sqrt(square(9.0035 - x₁))\n",
            "6           6.730e+03  1.316e-03  y = x₃ / (square(1.8057) - x₂)\n",
            "7           6.588e+03  2.124e-02  y = 0.3725 / (x₂ - (x₃ / 0.27882))\n",
            "18          6.565e+03  3.165e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "19          6.561e+03  5.868e-04  y = sqrt(x₃) / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.329...\n",
            "                                  2) * sqrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 4.690e+04\n",
            "Head worker occupation: 9.6%\n",
            "Progress: 1933 / 20000 total iterations (9.665%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.983e-04  y = 3.3024 - x₂\n",
            "4           6.740e+03  8.381e-05  y = square(3.8329 - x₂)\n",
            "5           6.738e+03  2.960e-04  y = sqrt(square(9.0035 - x₁))\n",
            "6           6.730e+03  1.316e-03  y = x₃ / (square(1.8057) - x₂)\n",
            "7           6.588e+03  2.124e-02  y = 0.3725 / (x₂ - (x₃ / 0.27882))\n",
            "18          6.565e+03  3.165e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "19          6.561e+03  5.868e-04  y = sqrt(x₃) / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.329...\n",
            "                                  2) * sqrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n",
            "\n",
            "Expressions evaluated per second: 3.770e+04\n",
            "Head worker occupation: 9.6%\n",
            "Progress: 1979 / 20000 total iterations (9.895%)\n",
            "====================================================================================================\n",
            "Hall of Fame:\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Complexity  Loss       Score     Equation\n",
            "1           6.745e+03  1.594e+01  y = 0.3958\n",
            "3           6.741e+03  2.983e-04  y = 3.3024 - x₂\n",
            "4           6.740e+03  8.381e-05  y = square(3.8329 - x₂)\n",
            "5           6.738e+03  2.960e-04  y = sqrt(square(9.0035 - x₁))\n",
            "6           6.730e+03  1.316e-03  y = x₃ / (square(1.8057) - x₂)\n",
            "7           6.588e+03  2.124e-02  y = 0.3725 / (x₂ - (x₃ / 0.27882))\n",
            "18          6.565e+03  3.165e-04  y = x₃ / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.3292) * s...\n",
            "                                  qrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "19          6.561e+03  5.868e-04  y = sqrt(x₃) / (((square(sqrt(sqrt(0.44394) * 0.86423) + 1.329...\n",
            "                                  2) * sqrt(0.44394)) + sqrt(0.44394)) - x₂)\n",
            "---------------------------------------------------------------------------------------------------\n",
            "====================================================================================================\n",
            "Press 'q' and then <enter> to stop execution early.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(model.sympy(i))\n",
        "  y_pred = model.predict(X,i)\n",
        "  print(\"Default selection MSE:\", np.power(y_pred - y, 2).mean())\n",
        "  r2 = r2_score(y_pred, y)\n",
        "  print(f\"R²: {r2:.4f}\")\n",
        "  x_line = [0.9, 1.8]\n",
        "  y_line = [0.9, 1.8]\n",
        "  fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(5, 5), constrained_layout = True)\n",
        "  ax1.scatter(x=y, y=y_pred, marker='o', c='none', edgecolor='b', label='Exterior Girder')\n",
        "  ax1.plot(x_line, y_line, c = \"k\")\n",
        "  ax1.set_title('Accuracy')\n",
        "  ax1.legend()\n",
        "  plt.xlim((0.9,1.8))\n",
        "  plt.ylim((0.9,1.8))\n",
        "  ax1.set_xlabel('Target $n_{r1}$')\n",
        "  ax1.set_ylabel('Predicted $n_{r1}$')\n",
        "  ax1.grid()"
      ],
      "metadata": {
        "id": "xCUaIxWtniLv"
      },
      "id": "xCUaIxWtniLv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pkl_file = \"skew_correction_V_G2.pkl\"\n",
        "\n",
        "with open(model_pkl_file, 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "Qz3iZfGEqbeX"
      },
      "id": "Qz3iZfGEqbeX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.stack((x_L, x_S, x_w_oh, x_tan_skew), axis=-1)\n",
        "y = sk_bm1_correction\n",
        "model.fit(X, y)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "Z7K5n8oJtSo0"
      },
      "id": "Z7K5n8oJtSo0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pkl_file = \"skew_correction_M_G1.pkl\"\n",
        "\n",
        "with open(model_pkl_file, 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "dvhFPuBntYXK"
      },
      "id": "dvhFPuBntYXK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.stack((x_L, x_S, x_w_oh, x_tan_skew), axis=-1)\n",
        "y = sk_bm2_correction\n",
        "model.fit(X, y)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "AXCPfXP6tXAa"
      },
      "id": "AXCPfXP6tXAa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pkl_file = \"skew_correction_M_G2.pkl\"\n",
        "\n",
        "with open(model_pkl_file, 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "7lW0Zj4qteiZ"
      },
      "id": "7lW0Zj4qteiZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}